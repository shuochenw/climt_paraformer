{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f7f299b-0870-47d1-8945-51b66b799d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T18:57:54.785576Z",
     "iopub.status.busy": "2025-10-13T18:57:54.785315Z",
     "iopub.status.idle": "2025-10-13T18:57:54.790044Z",
     "shell.execute_reply": "2025-10-13T18:57:54.789612Z",
     "shell.execute_reply.started": "2025-10-13T18:57:54.785559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA H200\n",
      "Memory Usage:\n",
      "Allocated: 0.1 GB\n",
      "Cached:    0.1 GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR, CosineAnnealingLR\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ca3c88c-818f-44cd-818c-59e595d6f460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T18:57:54.997628Z",
     "iopub.status.busy": "2025-10-13T18:57:54.997317Z",
     "iopub.status.idle": "2025-10-13T18:57:55.000067Z",
     "shell.execute_reply": "2025-10-13T18:57:54.999684Z",
     "shell.execute_reply.started": "2025-10-13T18:57:54.997612Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'Transformer'\n",
    "SEQUENCE_SIZE = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 512\n",
    "# run for 10 epochs for demostration, the actual epoch is 200\n",
    "EPOCHS = 10\n",
    "IN_FEATURES = 124\n",
    "OUT_FEATURES = 128\n",
    "D_MODEL = 256\n",
    "# DROPOUT = 0.2\n",
    "N_HEAD = 4\n",
    "N_LAYER = 6\n",
    "MAX_LEN = SEQUENCE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d424508-a55c-4816-b592-f473549a6428",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T18:57:56.121974Z",
     "iopub.status.busy": "2025-10-13T18:57:56.121620Z",
     "iopub.status.idle": "2025-10-13T18:57:59.653688Z",
     "shell.execute_reply": "2025-10-13T18:57:59.653259Z",
     "shell.execute_reply.started": "2025-10-13T18:57:56.121950Z"
    }
   },
   "outputs": [],
   "source": [
    "# use all 8 years: change path\n",
    "X_train=np.load('/projects/sds-lab/Shuochen/climsim/train_input.npy')\n",
    "y_train=np.load('/projects/sds-lab/Shuochen/climsim/train_target.npy')\n",
    "X_test=np.load('/projects/sds-lab/Shuochen/climsim/val_input.npy')\n",
    "y_test=np.load('/projects/sds-lab/Shuochen/climsim/val_target.npy')\n",
    "X_scoring = np.load('/projects/sds-lab/Shuochen/climsim/scoring_input.npy')\n",
    "y_scoring = np.load('/projects/sds-lab/Shuochen/climsim/scoring_target.npy')\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)\n",
    "X_scoring = torch.Tensor(X_scoring)\n",
    "y_scoring = torch.Tensor(y_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88502976-7784-46a3-bfcf-b158501025b6",
   "metadata": {},
   "source": [
    "# create windows for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "176be2a7-4e9c-4f97-99ca-2335e5ddbb20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T18:58:00.636205Z",
     "iopub.status.busy": "2025-10-13T18:58:00.635934Z",
     "iopub.status.idle": "2025-10-13T18:58:03.902405Z",
     "shell.execute_reply": "2025-10-13T18:58:03.901894Z",
     "shell.execute_reply.started": "2025-10-13T18:58:00.636188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape:  torch.Size([10091520, 124]) torch.Size([10091520, 128])\n",
      "torch.Size([384, 26280, 124]) torch.Size([384, 26280, 128])\n",
      "original shape:  torch.Size([1441920, 124]) torch.Size([1441920, 128])\n",
      "torch.Size([384, 3755, 124]) torch.Size([384, 3755, 128])\n",
      "original shape:  torch.Size([1681920, 124]) torch.Size([1681920, 128])\n",
      "torch.Size([384, 4380, 124]) torch.Size([384, 4380, 128])\n",
      "torch.Size([2018304, 5, 124]) torch.Size([288384, 5, 124]) torch.Size([336384, 5, 124])\n",
      "torch.Size([2018304, 5, 128]) torch.Size([288384, 5, 128]) torch.Size([336384, 5, 128])\n"
     ]
    }
   ],
   "source": [
    "def slice_data(X, y):\n",
    "\n",
    "    print('original shape: ',X.shape,y.shape)\n",
    "    # to tensor, reshape, transpose (time * space, 124 or 128) > (space, time, 124 or 128)\n",
    "    X=X.reshape(int(X.shape[0]/384),384,124).permute(1,0,2)\n",
    "    y=y.reshape(int(y.shape[0]/384),384,128).permute(1,0,2)   \n",
    "    print(X.shape,y.shape)\n",
    "    # # create sliding window (space, time, 124 or 128) > (space, num_window, 124 or 128, seq_size)\n",
    "    # X = X.unfold(1,SEQUENCE_SIZE,SEQUENCE_SIZE)\n",
    "    # y = y.unfold(1,SEQUENCE_SIZE,SEQUENCE_SIZE)\n",
    "    # print(X.shape,y.shape)\n",
    "    X = X.reshape(384, int(X.shape[1] / SEQUENCE_SIZE), SEQUENCE_SIZE, 124)\n",
    "    y = y.reshape(384, int(y.shape[1] / SEQUENCE_SIZE), SEQUENCE_SIZE, 128)\n",
    "    # print(X.shape,y.shape)\n",
    "    X = X.flatten(0,1)\n",
    "    y = y.flatten(0,1)\n",
    "    # print(X.shape,y.shape)\n",
    "    return X, y\n",
    "\n",
    "# X, y = create_sliding_window(X, y)\n",
    "X_train, y_train = slice_data(X_train, y_train)\n",
    "X_test, y_test = slice_data(X_test, y_test)\n",
    "X_scoring, y_scoring = slice_data(X_scoring, y_scoring)\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_scoring.shape)\n",
    "print(y_train.shape, y_test.shape, y_scoring.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c7e0371-006a-4209-9719-aad9c8511e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T18:58:14.692236Z",
     "iopub.status.busy": "2025-10-13T18:58:14.691963Z",
     "iopub.status.idle": "2025-10-13T18:58:14.695546Z",
     "shell.execute_reply": "2025-10-13T18:58:14.694995Z",
     "shell.execute_reply.started": "2025-10-13T18:58:14.692220Z"
    }
   },
   "outputs": [],
   "source": [
    "# create datasets\n",
    "training_set = TensorDataset(X_train, y_train)\n",
    "testing_set = TensorDataset(X_test, y_test)\n",
    "scoring_set = TensorDataset(X_scoring, y_scoring)\n",
    "# create dataloaders\n",
    "train_dataloader = DataLoader(training_set, # dataset to turn into iterable\n",
    "    batch_size=BATCH_SIZE, # how many samples per batch? \n",
    "    shuffle=True # shuffle data every epoch?\n",
    ")\n",
    "test_dataloader = DataLoader(testing_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")\n",
    "scoring_dataloader = DataLoader(scoring_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56717934-1eeb-4a4b-b982-48c8a7f1af9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T17:16:37.535721Z",
     "iopub.status.busy": "2025-10-13T17:16:37.535419Z",
     "iopub.status.idle": "2025-10-13T17:16:37.539810Z",
     "shell.execute_reply": "2025-10-13T17:16:37.539339Z",
     "shell.execute_reply.started": "2025-10-13T17:16:37.535698Z"
    }
   },
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccac76a5-b23d-4311-a37b-dedfa073e7d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T18:58:20.100113Z",
     "iopub.status.busy": "2025-10-13T18:58:20.099840Z",
     "iopub.status.idle": "2025-10-13T18:58:20.133553Z",
     "shell.execute_reply": "2025-10-13T18:58:20.133166Z",
     "shell.execute_reply.started": "2025-10-13T18:58:20.100096Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model=D_MODEL, max_len=SEQUENCE_SIZE):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe\n",
    "        return x\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim=IN_FEATURES, output_dim = OUT_FEATURES, d_model=D_MODEL, \n",
    "                 nhead=N_HEAD, num_layers=N_LAYER):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding()\n",
    "        # self.pos_encoder = nn.Embedding(SEQUENCE_SIZE, d_model)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.decoder = nn.Linear(d_model, output_dim)\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.decoder_2 = nn.Linear(512, output_dim)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        # x = x+self.pos_encoder(torch.arange(SEQUENCE_SIZE, device=device))\n",
    "        x = self.transformer_encoder(x)\n",
    "        # x = self.decoder(x[:, -1, :])\n",
    "        x = self.decoder(x)\n",
    "        # x = self.relu(x)\n",
    "        # x = self.decoder_2(x)\n",
    "        return x\n",
    "\n",
    "model = TransformerModel().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "# scheduler is not used in this example\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2684319-ffcb-4cd9-ac3f-88b01d750249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T18:58:20.588243Z",
     "iopub.status.busy": "2025-10-13T18:58:20.587890Z",
     "iopub.status.idle": "2025-10-13T19:05:52.785320Z",
     "shell.execute_reply": "2025-10-13T19:05:52.784830Z",
     "shell.execute_reply.started": "2025-10-13T18:58:20.588226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.00666 | Test loss: 0.00447\n",
      "Epoch: 1 | Train loss: 0.00442 | Test loss: 0.00409\n",
      "Epoch: 2 | Train loss: 0.00404 | Test loss: 0.00381\n",
      "Epoch: 3 | Train loss: 0.00382 | Test loss: 0.00363\n",
      "Epoch: 4 | Train loss: 0.00368 | Test loss: 0.00353\n",
      "Epoch: 5 | Train loss: 0.00359 | Test loss: 0.00343\n",
      "Epoch: 6 | Train loss: 0.00352 | Test loss: 0.00339\n",
      "Epoch: 7 | Train loss: 0.00346 | Test loss: 0.00333\n",
      "Epoch: 8 | Train loss: 0.00342 | Test loss: 0.00330\n",
      "Epoch: 9 | Train loss: 0.00337 | Test loss: 0.00325\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "        y_pred = model(X.to(device))\n",
    "        loss = loss_fn(y_pred, y.to(device))\n",
    "        train_loss += loss # accumulatively add up the loss per epoch \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_loss_list.append(train_loss.detach().cpu().numpy())\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for X, y in test_dataloader:\n",
    "            test_pred = model(X.to(device))\n",
    "            test_loss += loss_fn(test_pred, y.to(device)) # accumulatively add up the loss per epoch\n",
    "        \n",
    "        # Divide total test loss by length of test dataloader (per batch)\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_loss_list.append(test_loss.detach().cpu().numpy())\n",
    "\n",
    "    print(f\"Epoch: {epoch} | Train loss: {train_loss:.5f} | Test loss: {test_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76e8b2-eeba-4939-b020-c90638f4d77d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef20cf-2bf8-43ab-9428-40adb05055c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b7005-2c7e-45b1-957c-264d6a28e519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e80569-bcfe-4481-b502-d026b2dcfe49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5910074c-636b-4eb6-a150-eeff4de82743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
